Análisis de la varianza (ANOVA): teoría y práctica
========================================================
author: Pablo Vinuesa, CCG-UNAM. http://www.ccg.unam.mx/~vinuesa/
date: 1 de Agosto de 2018
autosize: true 
width: 1920
height: 1080
navigation: section
transition: rotate
transition-speed: fast
font-family: "Helvetica"

## Presentación

Este tema es parte del [Taller 2 - Análisis exploratorio y estadístico de datos biológicos usando R](http://congresos.nnb.unam.mx/TIB2018/), impartido entre 30 de Julio y 3 de Agosto de 2018 en el [Centro de Ciencias Genómicas](www.ccg.unam.mx) de la [Universidad Nacional Autónoma de México](www.unam.mx). 

Para más información consultar la página del taller en: <http://congresos.nnb.unam.mx/TIB2018/t2-analisis-exploratorio-y-estadistico-de-datos-biologicos-usando-r/>.  

Esta presentación se distribuye desde el repositorio GitHub [curso_Rstats](https://github.com/vinuesa/curso_Rstats)

La parte teórica está basada en Crawley (2012, 2015), Field et al. (2012) y Kabacoff (2015).   

Este documento está aún en construcción y es generado con R (R Core Team 2016), rstudio (RStudio Team 2016), knitr (Xie 2016), rmarkdown (Allaire et al. 2016), pandoc (MacFerlane 2016) y LaTeX.

Usa CTRL+/CTRL- para ajustar tamaño a tu pantalla. Avanza/retrocede con las flechas.

1. Contenidos 
========================================================
type: section
* Preparación del ambiente
* Análisis de la varianza (ANOVA): teoría y práctica
* ANOVA de una vía - desarrollo gráfico y numérico del concepto
   + Cálculo manual de las tablas de ANOVA de una vía y su interpretación gŕafica
   + Cómputo de ANOVA simple en R con aov()
   + Validación de supuestos

* ANOVA de una vía - casos reales
    + Datos que no violan los supuestos: PlantGrowth
    + Alternativas al ANOVA cuando se violan los supuestos:

* Experimentos factoriales - ANOVA de doble vía
    + Estadísticas de resumen mediante tapply() y gráficos con barplot() (R base)                          2.4.3 ANOVA de doble vía: experimento factorial completo
    + ANOVA de doble vía con interacciones

1. Contenidos -- cont.
===============================
type: section
 * Funciones y paquetes de R usados para este documento
    + Paquetes y software para investigación reproducible y 
        generación de documentos en múltiples formatos
    + Paquetes de uso general para procesamiento y graficado de datos
    + Análisis de la varianza - ANOVA
        + Funciones de paquetes base (R Core Team 2018)
        + Datos del paquetes base
        + Paquetes especializados

* Recursos en línea
    + The comprehensive R archive network (CRAN)
    + Cursos
    + Consulta
    + Manipulación y graficado de datos con paquetes especializados

* Referencias



Preparación del ambiente
========================================================
## Carguemos los paquetes a usar en esta sesión

```{r}
# ipak function: install and load multiple R packages.
# check to see if packages are installed. Install them if they are not, then load them into the R session.

ipak <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE)
    sapply(pkg, require, character.only = TRUE)
}

# usage
packages <- c("ggplot2", "dplyr", "car", "gplots", "multcomp", "PMCMR", "ggpubr", "HH")
ipak(packages)
```

## Guardemos los parámetros gráficos originales en opar
```{r}
# guardemos los parámetros gráficos originales en opar
opar <- par(no.readonly = TRUE)
```


<!-- EXPLORAR: https://bioinformatics-core-shared-training.github.io/linear-models-r/ -->

<!-- Este documento fue generado con R [@R-base], rstudio [@RStudio], knitr [@R-knitr], rmarkdown [@R-rmarkdown], [pandoc](http://pandoc.org/) [@MacFerlane2016] y [$LaTeX$](https://www.latex-project.org/). -->


Introducción: el concepto y ámbito de aplicación del análisis de la varianza
========================================================
* El **análisis de la varianza o ANOVA** engloba a un conjunto de métodos estadísticos que usamos cuando la **variable de respuesta** es **contínua** pero **la(s) variable(s) explicativa(s) o independiente(s)** es (son) **categórica(s)**. 
* Las variables explicativas categóricas se conocen como **factores**, y cada factor tiene dos o más **niveles**. 
* Si tenemos una sola variable explicativa hablamos de **análisis de la varianza de una vía (1-way ANOVA)**. 
* Podemos considerar por tanto a la ANOVA de 1 vía como una genrealización de la *prueba t de Student*, cuando tenemos 3 o más niveles de la variable categórica y **queremos comparar 3 o más medias**. 
* Al igual que en la *prueba t de Student*, estamos interesados en analizar cómo se comporta la media de la variable de respuesta (numérica, contínua) en función de los diversos niveles de la variable categórica de agrupamiento. 
* Si tenemos más de una variable explicativa categórica, hablamos de **ANOVA de 2 o más vías**. 
* Si el diseño exprimental comprende réplicas en cada nivel de una ANOVA multivía, el diseño corresponde a **diseño factorial**, en cuyo caso podremos estudiar **interacciones entre variables**, con el fin de establecer si la respuesta a un factor depende a su vez del nivel de algún otro factor o variable explicativa.


ANOVA y Diseños experimentales: nomenclatura
========================================================
* El diseño experimental en general, y el análisis de la varianza en particular, tienen un lenguaje propio interrelacionado. Es un tópico vasto, con libros y paquetes de R dedicados a ello. 
* Un buen sitio para profundizar es este curso sobre [ANOVA and experimental designs](http://stat.ethz.ch/~meier/teaching/anova/index.html). Aquí sólo un breve resumen de conceptos y terminología claves adicionales a los arriba mencionados

- Diseños
pueden ser *balanceados* (iqual número de réplicas por tratamiento/nivel del factor) o *desbalanceados*

- Contrastes
pueden ser *entre grupos* o *intra-grupo*, en este último caso generalmente asociado a *ANOVA de medidas repetidas* a lo largo del tiempo sobre un mismo individuo.

- Diseños fatctoriales. Cuando evaluamos los efectos sobre la variable de respuesta de dos o más factores, cada uno con dos o más niveles. Los *efectos principales* son los que podemos asignar a cada factor, mientas que los *efectos de interacción* se deben a las interacciones entre los niveles de cada factor analizado

- Modelos mixtos. Cuando en un diseño factorial evaluamos tanto contrastes *inter-grupo* como *intra-grupo*

- ANCOVA o análisis de la co-varianza. Cuando tenemos una segunda variable cuantitativa contínua (no un factor!) que pudiera afectar a las diferencias entre grupos de la variable de respuesta, se la considera una *variable o factor confusor* 

- MANOVA o análisis multivariado de la varianza. Cuando tenemos más de una variable dependiente. Si además tenemos co-variables, tendríamos una *análisis multivariado de co-varianza* o *MANCOVA*. 

Aquí veremos sólo algunos de estos casos o modelos.


Sintaxis de fórmulas para ajuste de modelos ANOVA a diversos diseños experimentales
========================================================
Históricamente, si bien el *análisis de la varianza* se desarrolló independientemente de las metodologías de *regresión*, ambos representan casos especiales del **modelo lineal**. 

Por tanto, como veremos, podemos usar tanto la función $aov()$ como $lm()$ para ajustar y analizar modelos de ANOVA. 

Nos enfocaremos primero en $aov()$, que reporta la salida en un formato "clásico", basado en la *tabla de ANOVA*

La sintaxis básica para llamar a $aov()$ es:

$$\displaystyle aov(formula,\ data=dataframe)$$

Símbolos y sintaxis de $formulas\ para\ ANOVA$
========================================================
|Símbolo |uso
:--|:-------------------------------------------------------------------------------------
~ |Separa la variable de respuesta a la izquierda de las variables explicativas o independientea a la derecha. Ejemplo: $y\ \tilde\  A + B$. Predicción de respuesta de y en función de los factores A y B.
+ |Separa los factores, como en  $y\ \tilde\  A + B + C$          
: |Denota interacción entre variables en un diseño factorial, como en $y\ \tilde\  A + B + A:B$
* |Denota el cruzamiento (interacciones) total entre variables. $y\ \tilde\ A*B*C$ expande a $y\ \tilde\  A + B + A:B + A:C + B:C + A:B:C$
^ |Denota cruzamiento hasta un determinado nivel de interacciones. $y\ \tilde\ (A*B*C)\^\ 2$ expande a $y\ \tilde\  A + B + A:B + A:C + B:C$
. |Denota el resto de las variables o todas las variables. $y\ \tilde\  .$ expande a $y\ \tilde\  A + B + C$

Fórmulas para ANOVA de diseños experimentales comunes
========================================================

|Diseño                                           |Fórmula
:-------------------------------------------------|:--------------------------------------
ANOVA de una vía                                  | $y\ \tilde\  A$
ANCOVA de una vía con una covariable $x$          | $y\ \tilde\ x + A$
ANOVA factorial de dos vías                       | $y\ \tilde\ A * B$
ANCOVA de dos vías con dos covariables $x_1,x_2$  | $y\ \tilde\ x_1 + x_2 + A * B$
ANOVA de una vía intra-grupo                      | $y\ \tilde\  A + Error(Sujeto/A)$      

#### Sobre la importancia del órden de los términos en las fórmulas para ANOVA
El orden importa si:
1. hay más de un factor y el diseño es desbalanceado
2. hay covariables

<small>
Cuando se cumple cualquiera de estas condiciones, las variables en el lado derecho de la fórmula estarán correlacionadas, por lo que no hay manera unívoca de dividir su impacto sobre la variable dependiente. Es decir, en una ANOVA de doble vía con número desigual de observaciones en las combinaciones de tratamientos, el modelo $y\ \tilde\ A * B$ dará el mismo resultado que $y\ \tilde\ B * A$. 

Por defecto, R usa la *aproximación secuencial* ("Type I") al cálculo de efectos en ANOVA, en el que son ajustados para aquellos que aparecen primero (secuencialmente) en la fórmula. Es decir, $A$ está desajustado. B se ajusta por A. La interacción $A:B$ es ajustada por $A$ y por $B$

A mayor desbalance, mayor impacto del órden de los términos en el resultado. En general, los efectos más importantes deben listarse primero. En particular, si hay co-variables, éstas deben ir primero, seguidas de los efectos principales, seguido de las interacciones entre pares, luego interacciónes de tres vías, etc. 

En resumen, cuando el *diseño es ortogonal*, es decir, cuando los factores y/o covariables están correlacionados, hay que tener cuidado y considerar el órden el el que se especifican los efectos.
</small>


Conceptos previos básicos - Varianza
========================================================
right: 70%

Es fundamental entender el concepto de **varianza** para poder hacer una ANOVA. Recordemos que la $\displaystyle varianza (s^2)$ es una medida de dispersión fundamental en estadística, que representa la **desviación cuadrática media** de los datos con respecto a la media. 

Veamos un ejemplo muy sencillo: la $media$ y los $residuos$ asociados a 11 valores de una variable:

***

```{r chunk1, out.width = '850px', fig.retina = NULL, fig.align='center', echo=FALSE}
y <- c(13,7,5,12,9,15,6,11,9,7,12)

plot(1:11,y,ylim=c(0,20),pch=16,col="blue")
abline(h=mean(y),col="green")
for (i in 1:11) lines(c(i,i),c(mean(y),y[i]),col="red")

```

Conceptos previos básicos - Varianza, cont.
=============================================
right: 50%

Formalmente, la varianza se calcula dividiendo la suma de cuadrados $sum(y_i-\bar{y})^2$ entre los **grados de libertad = g.l.**

Los $g.l.$ corresponden al número de parámetros libres a estimar. 

Para la media $g.l. = (n-1)$, ya que la media es un parámetro estimado de los datos, por lo cual perdemos 1 g.l. 

<small>
$$\displaystyle Varianza(s^2) =  \frac{\sum(y_i-\bar{y})^2} {N-1} = \frac{\sum(y_i-\bar{y})(yi-\bar{y})} {N-1}\\$$
</small>

Para nuestro ejemplo, tenemos por tanto que:

***
```{r, echo=TRUE}
y <- c(13,7,5,12,9,15,6,11,9,7,12)
media <- mean(y)
n <- length(y)
cat("media = ", media, "; n = ", n, "\n")

# suma de cuadrados:
SS <- sum((y-mean(y))^2)
cat("SS = ", SS, "\n")

# y la varianza
varianza <- SS/(n-1)

cat("varianza = ", varianza, "\n")

# usando var() obtenemos el mismo valor ;)
var(y)
```


ANOVA de una vía - desarrollo gráfico y numérico del concepto
========================================================
- Al igual que en la prueba *t* de Student, el objetivo del ANOVA de 1 vía es determinar si existen diferencias significativas entre las medias de cada nivel de la variable explicativa. 

- Ello se determina calculando las **sumas de cuadrados** $SS_i$ asociadas a cada nivel. 

- Si son más pequeñas que la suma de cuadrados del promedio global $SSY$, la diferencia entre medias es significativa.


Cálculo manual de las tablas de ANOVA de una vía
========================================================
right:75
- Para simplificar al máximo, vamos a usar un factor con dos niveles nada más. 
- Supongamos que tenemos las medidas de concentración de ozono (partes por 100 millones, ppcm) de dos invernaderos (A y B) productores de lechugas.

Antes de proceder, veamos la estructura del archivo de entrada: nótese que tenemos 1 variable contínua $ozone$ y otra categórica $garden$ para definir grupos.
***
```{r, out.width = '600px', fig.retina = NULL, fig.align='center', echo=TRUE}
# leamos el archivo directamente desde una url
unavia <- read.csv("https://math.la.asu.edu/~coombs/ozone.txt", sep ="\t")

# veamos la estructura del dfr unavia
str(unavia)

# usando attach, añadimos los objetos creados por R directamente al "search path"
attach(unavia)

# veamos la cabecera de la tabla
head(unavia)
```


Cálculo manual de las tablas de ANOVA de una vía ...
============================================
right:75
Ahora la gŕafica de dispersión.

Vemos una dispersión notable, indicano que la varianza total de  $y$ es grande.
***
```{r, out.width = '800px', fig.retina = NULL, fig.align='center', echo=TRUE}
# hagamos un gráfico de dispersión
plot(1:20,ozone,ylim=c(0,8),ylab="y",xlab="order",pch=21,bg="red")
```


Cálculo manual de las tablas de ANOVA de una vía, cont.
=========================================== 
right: 70%

* Visualizemos los resíduos para tener una mejor apreciación del nivel de varianza global en los datos.

* A esta dispersión global es a lo que llamamos **suma de cuadrados total** $SSY$

$$\displaystyle SSY = \sum(y_i-\bar{y})^2$$ 

*** 

```{r, out.width = '800px', fig.retina = NULL, fig.align='center', echo=TRUE}
plot(1:20,ozone, ylim=c(0,8), ylab="y", xlab="order", pch=21, bg="red")
abline(h=mean(ozone),col="blue")
for(i in 1:20) lines(c(i,i),c(mean(ozone),ozone[i]),col="green")
```


Cálculo manual de las tablas de ANOVA de una vía, cont.
===========================================
right: 70%

- Ahora vamos a ajustar la media correspondiente a cada nivel y visualizar las desviaciones de los datos con respecto a la media del tratamiento o nivel correspondiente. 

*** 

```{r, out.width = '800px', fig.retina = NULL, fig.align='center', echo=TRUE}
plot(1:20, ozone, ylim=c(0,8), ylab="y", xlab="order", pch=21, bg=c("blue", "red"))
abline(h=mean(ozone[garden == "A"]), col = "blue")
abline(h=mean(ozone[garden == "B"]), col = "red")
```

===========================================
right:75% 
- Nótese que si las medias de los tratamientos fueran iguales, entonces las líneas rojas y azules estarían en el mismo lugar, y por tanto la longitud de las líneas residuales sería la misma que en la figura anterior. 
- En cambio, si las medias fueran diferentes, las líneas residuales de los tramientos individuales serían menores que cuando las calculamos a partir de la muestra global. 
- Es decir **cuando las medias entre tratamientos son significativamente diferentes, las $SSi$ será menor que la $SSY$ calculada de la muestra global**.

***
<small>
```{r, out.width = '700px', fig.retina = NULL, fig.align='center', echo=TRUE}
# y ahora visualizemos los resíduos con respecto de las medias de los tratamientos 
# respectivos
plot(1:20, ozone, ylim=c(0,8), ylab="y", xlab="order", pch=21, bg=c("blue", "red"))
abline(h=mean(ozone[garden == "A"]), col = "blue")
abline(h=mean(ozone[garden == "B"]), col = "red")
index <- 1:length(ozone)

for (i in 1:length(index)){
  if (garden[i] == "A" )
     lines(c(index[i],index[i]),c(mean(ozone[garden=="A"]),ozone[i]), col = "blue")
  else 
     lines(c(index[i],index[i]),c(mean(ozone[garden=="B"]),ozone[i]), col="red")
}
```
</small>

Significancia de la diferencia entre SSs
========================================
La significancia de la diferencia entre estas dos $SSs$ se juzga mediante el análisis de la varianza. 

Para ello necesitamos calcular la **suma de cuadrado de los errores o desviaciones** $SSE$, que corresponde a la la suma de los cuadrados de las longitudes de las barras rojas más la suma de los cuadrados de las longitudes de las barras azules.

$$\displaystyle SSE = \sum\limits_{j=1}^k\sum(y-\bar{y_j})^2$$

Es decir, calculamos la media para el nivel $j_i$ del factor, y sumamos seguidamente los cuadrados de las diferencias, donde $SSE = varianza\ no\ explicada$ por los tratamientos.

**¿Cuántos grados de libertad están asociados al $SSE$?**

En nuestro caso tenemos $n = 10$ réplicas para cada uno de los $k = 2$ tratamientos ($k*n$ números en total). 

Como estimamos $k$ parámetros (medias en este caso), habremos perdido $k$ grados de libertad en el proceso, y los $g.l. = kn -k = k(n-1)$. 

Visto de otra manera, si tenemos $n$ réplicas en cada tratamiento, y por tanto $(n - 1)$ grados de libertad para el error en cada uno (perdemos 1 g.l. al estimar la media de cada tratamiento: $\bar y_i$). 

Por lo tanto, para $k$ tratamientos ($k$ niveles del factor), tenemos **$g.l. = k(n-1)$** para el error en el experimento global.

Particionado de la suma de cuadrados total SSY = SSA + SSE
=================================================
<small>
La suma de cuadrados total $SSY$ es particionada en sus componentes: la variación no explicada o error $SSE$ y la **suma de cuadrados de los tratamientos** $SSA$. Es decir $SSY = SSA + SSE$. 

Dado que podemos calcular $SSY$ y $SSE$ con las fórmulas arriba presentadas, calculamos $SSA$ (la variación explicada por las diferencias entre medias de los tratamientos) así:

$$\displaystyle SSA = SSY - SSE$$

- Cálculo de $SSY$
```{r, echo = TRUE}
SSY <- sum((ozone - mean(ozone))^2)
SSY
```

* Cálculo de $SSE$
Es la suma de cuadrados de los residuos calculada por separado para cada tratamiento, usando la media correspondiente.
 + Para el invernadero A:
```{r, echo = TRUE}
 ssa <- sum((ozone[garden=="A"] - mean(ozone[garden=="A"]))^2)
 cat("SS para A: ", ssa)
```
 + Para el invernadero B:
```{r, echo = TRUE}
 ssb <- sum((ozone[garden=="B"] - mean(ozone[garden=="B"]))^2)
 cat("SS para B: ", ssb)
```

Por tanto: $SSE = 12 + 12 = 24$ y $SSA = 44 - 24 = 20$
</small>

Particionado de la suma de cuadrados total SSY = SSA + SSE
====================================================
Ya tenemos los dos *componentes* ($SSA$ y $SSE$) en los que se descompone la variación total de los datos ($SSY$). 

Hagamos un *análisis de la varianza*, la famosa **ANOVA**, para comparar estos dos componentes mediante un cociente $F$ entre las varianzas asociadas a cada componente. 

Estadísticos como $F$ representan generalmente la cantidad de *varianza sistemática (del modelo o tratamienots) / varianza no sistemática (error de los datos)*, es decir $F$ se basa en la razón de $SSA/SSE$. 

Pero como las sumas de cuadrados dependen del número de puntos (diferencias sumadas), $F$ usa la *media de la suma de cuadrados*, $MS = promedio\ de\ suma\ de\ cuadrados$.

$$\displaystyle F = \frac{MS_M}{MS_E} = \frac{media\ de\ los\ cuadrados\ del\ modelo}{media\ cuadrados\ de\ los\ errores\ o\ resíduos}$$

donde $$\displaystyle MS_M = \frac{SSR}{g.l.} = \frac{SSR}{no.\ parámetros\ estimados\ en\ el\ modelo:\ b\ (1\ g.l.\ en\ ml\ simple)}$$ 

y $$\displaystyle MS_E=\frac{SSE}{g.l.} = \frac{SSE}{no.\ observaciones - no.\ parámetros\ libres:\ a,\ b\ (n-2)}$$

Construyamos la **tabla de ANOVA** correspondiente, paso a paso:

Construcción de la tabla de ANOVA
====================================================
 Ya tenemos calculados las sumas de cuadrados de cada fuente de variación, como se muestra abajo.

|Fuente            |Suma de cuadrados|Grados de libertad |Media de cuadrados (Varianza) |cociente $F$
:------------------|:----------------|:------------------|:-----------------------------|:-----------
Tratamiento        |20 ($SSA$)       |                  |                              |
Error (resíduos)   |24 ($SSE$)       |                  |                              |
Total (datos)      |44 ($SSY$)       |                  |                              |


Construcción de la tabla de ANOVA -- cont.
====================================================
Llenemos ahora la columna de los *grados de libartad* ($g.l.$). 

Recordemos que, esencialmente, los **grados de libartad** representan el número de 'entidades' que están libres de variar cuando estimamos algún parámetro estadístico a partir de los datos. 

Los $g.l$ se calculan como $n-número\ de\ parámetros\ libres\ a\ estimar\ de\ los\ datos$. 

Por tanto: 

- $g.l.(SSA) = k - 1  = 1$, ya que hay dos niveles del factor: A y B.
- $g.l.(SSE)$, dado que hay $n = 10$ replicas por nivel, tenemos que $g.l. = 10 -1)$ por invernadero, por tanto  $g.l.\ para\ SSE = 2\ x\ 9 = 18 = k(n-1)$.
- $g.l.(SSY) = n - 1$ del conjunto global de datos hemos estimado sólo un parámetro $(n = 20), la media global $\bar{y}$ $g.l. = 20 - 1 = 19$  

Noten que la suma de $g.l.(SSR) + g.l.(SSE) = g.l.(SSY$), como se ve en la tabla. 

|Fuente            |Suma de cuadrados|Grados de libertad |Media de cuadrados (Varianza) |cociente $F$
:------------------|:----------------|:------------------|:-----------------------------|:-----------
Tratamiento        |20 ($SSA$)       |1  ($k-1$)         |                              |
Error (resíduos)   |24 ($SSE$)       |18 ($k(n-1)$)      |                              |
Total (datos)      |44 ($SSY$)       |19 ($n-1$)         |                              |

Construcción de la tabla de ANOVA -- cont.
====================================================
Necesitamos llenar la 4a. columna, reservada para las varianzas. Recoredemos que: 

$$\displaystyle var = s^2 = \frac{suma\ de\ cuadrados}{grados\ de\ libertad}$$

Esta columna (4) es muy fácil de llenar, ya que tenemos los valores que necesitamos pre-calculados en las columnas 2 y 3. 

La $var\ total$ no nos hace falta, pero sí el $cociente-F = \frac{20}{1.333}$, que incluímos tambien en la **tabla de ANOVA**, completándola.

|Fuente            |Suma de cuadrados|Grados de libertad |Media de cuadrados (Varianza) |cociente $F$
:------------------|:----------------|:------------------|:-----------------------------|:-----------
Tratamiento        |20 ($SSA$)       |1  ($k-1$)         | $s^2 = 20$ (20 / 1)          | $20 / 1.333 = 15.0$
Error (resíduos)   |24 ($SSE$)       |18 ($k(n-1)$)      | $s^2 = 1.333$ (24 /18)       |
Total (datos)      |44 ($SSY$)       |19 ($n-1$)         |                              |

Construcción de la tabla de ANOVA -- cont.
====================================================
Calculemos ahora la significancia del $cociente-F$. Recordemos que: 

- $H_0: b = 0$, la pendiente de la recta de regresión es cero (el modelo no difiere de la media)
- $H_1: b\ne0$, usando una alternativa de doble cola asumimos que la pendiente es positiva o negativa 

Podemos buscar el **valor crítico de $F$** en la tabla correspondiente, usando ${g.l.}_{numerador} = 1$ y ${g.l.}_{denominador} = 18$ y veríamos algo como ésto:

|$g.l.(denom)$|p  |**1** ... ($g.l.(num.)$)
:------|:---------|:------
1      |0.05      | 161.45
1      |0.01      | 4052.18
...    |...       | ...
**18**      |0.05      | **4.41**
**18**      |0.01      | **8.29**

Dado que nuestro estadístico $F = 15$ es mucho mayor que el valor crítico de $F_{(1,18)}$, rechazamos la hipótesis nula con $p < .01$.

Significancia del cociente-F
====================================================
Pero estamos *aprendiendo estadística usando R*, ¿verdad? ¿O cargas contigo las tablas de valores críticos para múltiples estadísticos?

Recordemos que los **intervalos de confianza** se definen como *quantiles* del 95% ó 99%.

Podemos calcular los quantiles para $F$ usando la función $qf(.95,glNum,glDenom)$ o $qf(.99,glNum,glDenom)$. 

La $p$ asociada al estadístico $F$ la calculamos como $1-pf(F, glNum, glDenom)$, como se muestra seguidamente: 

```{r}
glNum <- 1
glDenom <- 18
Fratio <- 15

CI95_F <- qf(.95, glNum, glDenom)
CI99_F <- qf(.99, glNum, glDenom)

p <- 1-pf(Fratio,glNum,glDenom)

cat("CI95% = ", CI95_F, "| CI99% = ", CI99_F, " | p = ", p, "\n")

```

Por tanto, la probabilidad de observar un $cociente-F$ tan extremo (o más) como el observado ($F = 15$) si ambas medias fueran realmente iguales es de ~ 0.1%. Es decir, observar esta $F$ bajo la $H_0$ de no diferencia entre medias es muy poco probable, de hecho $p < 0.01$, por lo que rechazamos $H_0$ contundentemente.

Significancia del cociente-F -- cont
====================================================
right:75

Gráficamente, lo podemos representar con este código:

*** 
```{r, out.width = '850px', fig.retina = NULL, fig.align='center', echo=TRUE}
x <- seq(0, 18, .05)
plot(x, df(x,1,18), type="l", ylab="f(x)", xlab="x", 
     main = "F(1,18) distribution; qf(.95, 1, 18) = 4.413873")
abline(v = qf(.95,1,18), col = "red", lty = 2)
arrows(15,0.5, 15, .1)
```

Significancia del cociente-F -- cont
====================================================
right:80%
Podemos además generar unos boxplots para visualizar las diferencias entre tratamientos.

Noten el uso de $notch = TRUE$. 

Cuando los *notches* no solapan, las diferencias en las medianas son probablemente significativas

$$notch = \pm{1.58} \frac{IQR}{\sqrt{n}}$$

***
```{r, out.width = '900px', fig.retina = NULL, fig.align='center', echo = TRUE}
plot(ozone~garden, notch = TRUE, col = c("blue", "tomato"))
```


Cómputo de ANOVA simple en R con aov()
===========================================================
R hace muy fácil este cálculo usando la función stats::aov() del paquete base stats, ahorrándonos mucho trabajo. 

La sintaxis básica para usar la función es $aov(formula,\ data=dataframe)$ 

Veremos más adelante algunos detalles sobre $formulas$ en R. 

Para la ANOVA de 1 vía la fórmula es $y\ \tilde\ A$, donde $y$ es la variable dependiente y $A$ el factor, como muestra la siguiente llamada:


```{r, echo = TRUE}
# var_dep ~ factor
summary(aov(ozone ~ garden))
```

Cómputo de ANOVA simple en R con aov()
===========================================================
$summary(aov())$ imprime la tabla de ANOVA. Como ven, los resultado son iguales a los que calculamos a mano. 

Recordemos que la $prueba\ t\ de\ Student$ es equivalente al ANOVA de una vía cuando el factor tiene dos niveles. 

Podemos comprobarlo fácilmente con el siguiente código:

```{r, echo = TRUE}
t.test(ozone[garden=="A"],ozone[garden=="B"])
```

Validación gráfica de supuestos con plot(aov())
===========================================================
right: 70%
<small>
Todos los tests estadísticos que hacen uso de la varianza se basan en **dos supuestos**: 

1. la **constancia u homogeneidad de varianzas entre tratamientos (niveles)**
2. **normalidad de los errores**

Análisis gráfico con $plot(aov())
- Gráfico 1 muestra que las varianzas son iguales en los dos tratamientos, que es lo ideal. 
- G2 muestra una relación razonablemente lineal en plot de quantiles-quantiles normales, indicando que la no-normalidad de los errores no es un problema en este caso. 
- G3 muestra los residuos contra los valores ajustados a una escala diferente, indicando nuevamente varianza constante. 
- G4 muestra las distancias de Cook, indicando que los puntos 8, 13 y 14 tienen residuos notoriamente grandes.

***

```{r, out.width = '850px', fig.retina = NULL, fig.align='center', echo = TRUE}
par(mfrow=c(2,2))
plot(aov(ozone~garden))
par(opar)
```
</small>

test de Levene de homogeneidad de las varianzas 
===============================================================
Validación de supuestos *homogeneidad de las varianzas* entre grupos con el **test de Levene**

La sintaxis básica del test, según se implemente en el paqute $car$ es: 

$car::leveneTest(value\ \tilde\ variable, dataset)$

```{r}
#  vean las opciones del test ?car::leveneTest
car::leveneTest(ozone ~ garden, data = unavia)
```

En consonancia con lo visto en el primer gráfico de arriba, las varianzas son iguales. 

Esto se refleja en la Pr(>F) = 1

Test Shapiro-Wilk de normalidad
================================================================= 

## Validación de supuesto de *normalidad* de la variable de respuesta

La sintaxis básica es: 

$shapiro.test(x)$, donde x es un vector de datos numéricos

```{r}
# vean las opciones del test con ?shapiro.test o help("shapiro.test")
shapiro.test(unavia$ozone)

# ya no vamos ausar mas el data frame 'unavia'. Conviene eliminarlo del search() path con detach()
detach(unavia)
```

Con una $p-value = 0.6495$ obviamente no podemos rechazar la $H_0$ de normalidad.

Por tanto, no hay problemas obvios en nuestros los datos.

ANOVA de una vía - casos reales: PlantGrowth
============================================================
## Datos que no violan los supuestos: $PlantGrowth$

Vamos a usar ahora el data frame $PlantGrowth$ que viene con la distribución base de R y contiene los resultados de un experimento diseñado para comparar los rendimientos (medidos como pesos secos) de plantas cultivadas bajo una condición control y dos tratamientos.

Es un *diseño balanceado*, ya que cada tratamiento contiene 10 observaciones. 

Como sólo tenemos una variable contínua y una categórica, se trata de un *análisis de la varianza de una vía*. 

Como vamos a comparar entre grupos, se trata de un *análisis inter-grupal de la varianza de una vía, con diseño balanceado*. 

Carguemos y exploremos la estructura de los datos

```{r, echo=TRUE}
pg_dfr <-  PlantGrowth
class(pg_dfr)
dim(pg_dfr)
names(pg_dfr)
```

ANOVA de una vía - PlantGrowth
===============================================
right: 70%

- Carguemos y exploremos la estructura de los datos ... cont

***
<small> 
```{r, echo=TRUE}
head(pg_dfr)
str(pg_dfr)
levels(pg_dfr$group)
```
</small>


ANOVA de una vía - PlantGrowth -- cont.
===============================================
right:75%
Generemos unas estadísticas descriptivas de los datos para tener una primera impresión acerca de medidas de tendencia central y dispersión.

Vemos que las varianzas no son iguales y que las distribuciones están ligeramente sesgadas (medias y medianas no coinciden). 

***
```{r, echo=TRUE}
#pg_dfr$group <- ordered(pg_dfr$group,
#                         levels = c("ctrl", "trt1", "trt2"))
# paquete dplyr
group_by(pg_dfr, group) %>%
  summarise(
    count = n(),
    media = mean(weight, na.rm = TRUE),
    mediana = median(weight, na.rm = TRUE),
    varianza = var(weight, na.rm = TRUE)
  )

```


ANOVA de una vía - PlantGrowth -- cont.
===============================================
right:60
Hagamos unas pruebas estadísticas de normalidad y homogeneidad de varianzas, para ver si son significativas o no estas desviaciones de las respectivas $H_0$.

Prueba de normalidad de Shapiro-Wilk 

Prueba no significativa
***
```{r, out.width = '500px', fig.retina = NULL, fig.align='center', echo = TRUE}
shapiro.test(PlantGrowth$weight)
```


ANOVA de una vía - PlantGrowth -- cont.
===============================================
right:75
Gráfica quantil-quantil del paquete $car::qqPlot$

Desvío mínimo de la normalidad
***
```{r, out.width = '850px', fig.retina = NULL, fig.align='center', echo = TRUE}
car::qqPlot(lm(weight ~ group, data = PlantGrowth), simulate = TRUE, 
       main = "Q-Q Plot", labels = FALSE)
```


ANOVA de una vía - PlantGrowth -- cont.
===============================================
right:70
Prueba de homogeneidad de varianzas de Levene

Ninguna de las dos pruebas es significativa, y el análisis de Q-Q muestra desviacíon mínima de la normalidad, por tanto podemos proceder al ANOVA.
***
```{r}
car::leveneTest(weight ~ group, data = PlantGrowth)
```


ANOVA de una vía - PlantGrowth -- cont.
===============================================
right:70%
ANOVA de una vía del data frame PlantGrowth

Recordemos que una ANOVA produce un $estadístico\ F$ o $cociente\ F$, similar al usado en la $prueba\ t\ de\ Student$, que corresponde al cociente $F = \frac{modelo} {error}$ que compara la varianza sistemática en los datos a la no sistemática. 

La $H_0$ es la de no diferencia entre medias de los tratamientos. 

En nuestro caso la $F$ es significativa.

***

```{r}
aov_pg <- aov(weight ~ group, data = PlantGrowth)
summary(aov_pg)
```
 
ANOVA de una vía - PlantGrowth -- cont.
===============================================
**¿Cómo reportar los resultados de una ANOVA de una vía?**

Obviamente debemos dar los detalles del $cociente\ F$ y los grados de libertad a partir de los cuales fue calculado. 

En nuestro caso: ${gl}_M = 2$ y ${gl}_R = 27$

En conclusión: hubo un efecto significativo de los tratamientos sobre el peso seco medio de las plantas, $F(2,27) = 4.846, p < .05$

ANOVA como un caso particular de regresión lineal
===============================================
right:75%
**Estima del tamaño de los efectos**

Generalmente es más informativo investigar los efectos de los diferentes niveles de un factor usando las funciones $summary.lm()$ y $coef()$ así:

***
<small>
```{r}
summary.lm(aov_pg)

coef(aov_pg)
```
</small>

ANOVA como un caso particular de regresión lineal  -- cont.
===============================================
El resultado de $summary.lm()$ viene de evaluar el modelo $aov(y~x)$, que es análogo al modelo lineal $y = a + {bx}_1 + {cx}_2$, donde $a$ (Intercept) es la media, en este caso del tratamiento $control$ (por convención, el primero de los niveles en orden alfabético), y $grouptrt1$ y $grouptrt2$ las diferencias de las correspondientes medias respecto al control. 

El $error\ estandar$ de $intercept$ es por tanto el $error\ estandar$ de la media: 

$$\displaystyle {SE}_{\bar{y}} = \sqrt{\frac{{s^2}_{a}} {n_a}} = \sqrt{\frac{0.6234^2} {10}} = 0.1971$$

mientras que los $errors\ estandar$ de las otras filas corresponde al de diferencia entre medias: 

$$\displaystyle {SE}_{diff} = \sqrt{2\frac{{s^2}_a} {n_a}} = \sqrt{2\frac{0.6234^2}  {10}} = 0.2788$$

La salida de $coef()$ nos dice, en resumen, que el tratamiento control tiene asociado un rendimiento promedio de 5.032. El efecto del tratamiento 1 (trt1) es reducir el peso en -0.371, y el del tratamiento 2 en incrementarlo en 0.494 unidades por encima del control.



Graficado de resultados y pruebas post-hoc -- cont.
=================================================
right:83%
El ANOVA es un test del efecto global de los tratamientos, y no da información sobre qué tratamientos particulares son los que tienen efectos significativos 

Necesitamos graficar los resultados para descubrir cuáles tienen un efecto significativo

Graficado de los datos mediante boxplots paralelos:
*** 
<small> 
```{r, out.width = '700px', fig.retina = NULL, fig.align='right', echo = TRUE}
bp <- ggplot(PlantGrowth, aes(x=reorder(group, weight, FUN = median), y=weight, fill=group)) + geom_boxplot() + geom_dotplot(binaxis = "y", stackdir = "center") +
  stat_summary(fun.y = "mean", geom="point", shape=23, size=4, fill = "black") 

bp + theme(axis.text.x = element_text(angle = 35, hjust = 1, vjust = 1, size = rel(1.5))) +
  ggtitle("Plant Growth experiment")
```
</small>

Graficado de resultados y pruebas post-hoc -- cont.
=================================================
right:80%

Graficado de medias por tratamiento con **intervalos de confianza del 95%**

El paquete $gplots$ puede ser útil para ésto

***
<small>
```{r, out.width = '850px', fig.retina = NULL, fig.align='right', echo = TRUE}
# library(gplots)
gplots::plotmeans(weight ~ group, data = PlantGrowth, xlab = "Tratamiento", 
          ylab = "Peso seco", main = "Medias con IC 95%")
```
</small>

Graficado de resultados y pruebas post-hoc -- cont.
=================================================
right:40%
**Prueba post-hoc HSD de Tukey**

Esta es muy conveniente para determinar diferencias significativas entre tratamientos.

En la gráfica, los intervalos de confianza que incluyen el 0 indican que los pares de tratamientos correspondientes no son significativamente diferentes ($p > 0.05$)
<small>
```{r}
TukeyHSD(aov_pg)
```
</small>

  ***
  
```{r, out.width = '850px', fig.retina = NULL, fig.align='center', echo = TRUE}
plot(TukeyHSD(aov_pg))
```


Graficado de resultados y pruebas post-hoc -- cont.
=================================================
right:75%
<small>
## Función $glht()$ del paquete $multcomp$ 

Evaluación de diferencias con Tukey's Honestly Significant Differences $HSD$

El paquete $multcomp$ incluye muchos métodos para el análisis de múltiples comparaciones, que pueden aplicarse tanto a modelos lineales como a modelos lineales generalizados. 

El siguiente ejemplo muestra cómo reproducir la anterior $prueba\ HSD\ de\ Tukey$ pero usando un despliegue gráfico más claro. Se trata de $pruebas\ t$ pareadas, con corrección para el múltiple testado.

Los grupos (boxplots) que comparten letra no son significativamente diferentes entre ellos.

Ambas representaciones indican que sólo las medias de los tratamientos 1 y 2 difieren significativamente entre ellas, pero ninguna con respecto al control.

***

```{r, out.width = '700px', fig.retina = NULL, fig.align='center', echo = TRUE}
# test post-hoc de Tukey
tuk <- glht(aov_pg, linfct=mcp(group="Tukey"))

# resumen del test
summary(tuk)
```
</small>

Graficado de resultados y pruebas post-hoc -- cont.
=================================================
right:45%
<small>
## Función $multcomp::glht$, cont.

Evaluación de diferencias con Tukey's Honestly Significant Differences $HSD$

Los grupos (representados por boxplots) que comparten letra no son significativamente diferentes entre ellos.

Ambas representaciones indican que sólo las medias de los tratamientos 1 y 2 difieren significativamente entre ellas, pero ninguna con respecto al control.

```{r}
# obtener los intervalos de confianza con confint()
confint(tuk)
```
</small>
***
<small>
```{r, out.width = '800px', fig.retina = NULL, fig.align='center', echo = TRUE}
# graficado
plot(cld(tuk, level = .05))
```
</small>

Graficado de resultados y pruebas post-hoc -- cont.
=================================================

Otra opción muy similar es usar la función $pairwise.t.test()$ usando *corrección de Bonferroni*:
```{r}
pairwise.t.test(PlantGrowth$weight, PlantGrowth$group, p.adj="bonferroni")
  
```

Pruebas no paramétricas
=======================================================
## Alternativas al ANOVA cuando se violan los supuestos: 

Volvamos a cargar los datos $ozono$ usados al inicio, y agregarle los datos correspondientes a un nuevo nivel $C$ de la variable $garden$

</small>
```{r}
# leamos el archivo directamente desde una url
ozono <- read.csv("https://math.la.asu.edu/~coombs/ozone.txt", sep ="\t")

# veamos la estructura del dfr ozono
str(ozono)

# veamos la cabecera de la tabla
head(ozono, n = 6L)

```
</small>

Pruebas no paramétricas -- cont
=======================================================
## Alternativas al ANOVA cuando se violan los supuestos: 
<small>
```{r}
# vamos a agregarle los datos correspondientes a un nuevo nivel "C" de la variable garden
ozono_gC <- c(3,3,2,1,10,4,3,11,3,10)
gC <- rep("C", 10)

# agrupamos los dos vectores en un data frame, le agregamos colnames() y lo gegamos
# como nuevas filas al data frame ozono con rbind()
gC_dfr <- data.frame(ozono_gC, gC)
colnames(gC_dfr) <- c("ozone", "garden")
str(gC_dfr)

ozono <- rbind(ozono, gC_dfr)

# veamos nuevamente la cabecera de la tabla
head(ozono, n = 4L)
```
</small>

Pruebas no paramétricas -- cont.
=======================================================
## Alternativas al ANOVA cuando se violan los supuestos: 

Grafiquemos unos boxplots para resumir las distribuciones de los datos por variable de agrupación.

```{r, out.width = '820px', fig.retina = NULL, fig.align='center', echo=TRUE}
# hagamos un gráfico de dispersión
plot(ozone ~ garden, data = ozono)

```

Pruebas no paramétricas -- cont.
=======================================================
## Alternativas al ANOVA cuando se violan los supuestos: 
Generemos unas estadísticas descriptivas ...

```{r}
ozono %>% group_by(garden) %>% summarize(n = n(),
                                         media = mean(ozone, na.rm = TRUE),
                                         mediana = median(ozone, na.rm = TRUE),
                                         varianza = var(ozone, na.rm = TRUE)
                                         )
```

Vemos que la varinza es un órden de magnitud mayor para el tratamiento C que para los demás. 

Pruebas no paramétricas -- cont.
=======================================================
right:60
## Alternativas al ANOVA cuando se violan los supuestos: 

**Prueba de normalidad de Shapiro-Wilk**

```{r}
shapiro.test(ozono$ozone)
```

***
**Prueba de homogeneidad de varianzas** entre el tratamientos
```{r}
gardenA <- ozono[ozono$garden == "A",]
gardenB <- ozono[ozono$garden == "B",]
gardenC <- ozono[ozono$garden == "C",]

var.test(gardenB$ozone, gardenC$ozone)
```

Pruebas no paramétricas -- cont.
=======================================================
## Alternativas al ANOVA cuando se violan los supuestos: 

Vemos que las varianzas son significativamente diferentes $p < .01$. 

Los jardines A y B tienen diferente media, pero idéntica varianza. 

Pero al comparar B con C, vemos que aunque ambos tiene la misma media, tienen varianzas muy diferentes. 

¿Son idénticas dos muestras con igual media? **NO**.

El umbral de daño por ozono está en 8 pphm. Ambas medias son claramente menores a este umbral. No obstante, explorando los datos crudos es claro que las lechugas del invernadero C estuvieron estuvieron expuestas en 30% de los días a valores > al umbral, como se muestra seguidamente:

```{r}
ozono %>% filter(ozone > 8)
```

Por tanto, **cuando las varianzas son diferentes entre tratamientos, no deben compararse sus medias** De hacerlo, nos arriesgamos a llegar a una conclusión errónea.


Pruebas no paramétricas -- kruskal.test()
=======================================================
## Alternativas al ANOVA cuando se violan los supuestos: 

Como en nuestro caso no podemos asumir tampoco normalidad, debemos usar **pruebas no paramétricas**. 

Dado que en nuestro caso los grupos/tratamientos son independientes, podemos usar la $prueba\ de\ Kruskal-Wallis$, un equivalente no paramétrico de la ANOVA de una vía.

```{r}
# est no-parametrico de Kruskal-Walis
kruskal.test(ozone ~ garden, data = ozono)
```


Pruebas no paramétricas -- tests de Nemenyi y Dunn
=======================================================
## Alternativas al ANOVA cuando se violan los supuestos: 

Dado que el test de KW es significativo, es razonable correr ***pruebas post-hoc*** para ver qué tratamientos son significativos. 

Podemos hacerlo con el **Tukey y Kramer (Nemenyi) test**, o el **Dunn test**, implementados en el paquete $PMCMR$


```{r}
# pruebas post-hoc de Nemeny y Dunn para el test no-parametrico de Kruskal-Walis
# Ver vignette con vignette("PMCMR")
PMCMR::posthoc.kruskal.nemenyi.test(x=ozono$ozone, g=ozono$garden, dist="Tukey" )
```

Pruebas no paramétricas -- tests de Nemenyi y Dunn
=======================================================
## Alternativas al ANOVA cuando se violan los supuestos:
```{r}
PMCMR::posthoc.kruskal.dunn.test(ozone ~ garden, data = ozono, 
                                 p.adjust.method="bonferroni")
```

Queda claro por ambos tests *post-hoc* que sólo es significativa la diferencia entre los tratamientos o niveles A-B

Pruebas no paramétricas -- prueba de Wilcox pareada
=======================================================
## Alternativas al ANOVA cuando se violan los supuestos: 

También podemos usar la **prueba de Wilcox pareada**, aplicando **correcciones para múltiples comparaciones**
```{r}
# rueba de Wilcox pareada, en este caso usando BH = fdr
# The false discovery rate is a less stringent condition than the family-wise error rate, 
#   so these methods are more powerful than the others
# Usa ?p.adjust.method para ver las opciones
pairwise.wilcox.test(ozono$ozone, ozono$garden, p.adjust.method = "BH")
```


Pruebas no paramétricas -- El paquete ggpubr
=======================================================
right:75

## Alternativas al ANOVA cuando se violan los supuestos: 

El paquete *ggpubr* tiene funciones muy convenientes para analizar y graficar resultados de pruebas de *ANOVA*, *Kruskal-Walis* y *tests post-hoc* asociados.

***
<small>
```{r, out.width = '850px', fig.retina = NULL, fig.align='center', echo=TRUE}
ggboxplot(ozono, x = "garden", y = "ozone",
          color = "garden", palette = "jco") + 
  stat_compare_means(method = "kruskal.test") # se puede cambiar por "anova"
```
</small>

Pruebas no paramétricas -- El paquete ggpubr
=======================================================
right:75
## Alternativas al ANOVA cuando se violan los supuestos: 

Es muy conveniente que el paquete *ggpubr* puede señalar gráficamente los resultados de las pruebas *post-hoc*.
***
<small>
```{r, out.width = '850px', fig.retina = NULL, fig.align='center', echo=TRUE}
my_comparisons <- list( c("A", "B"), c("B", "C"), c("A", "C") )
ggboxplot(ozono, x = "garden", y = "ozone",
          color = "garden", palette = "jco") + 
  stat_compare_means(comparisons = my_comparisons)+ # Add pairwise comparisons p-value
  stat_compare_means(label.y = 9)     # Add global p-value
```
</small>

Pruebas no paramétricas -- oneway.test()
=======================================================
## Alternativas al ANOVA cuando se violan los supuestos: 

Finalmente, si los datos:

1. no se desvían de la normalidad
2. pero las varianzas son heterogéneas

podemos correr también el $oneway.test()$, que tiene más potencia que el de *Kruskal-Walis*.

```{r}
oneway.test(ozone ~ garden, data = ozono)
```


Experimentos factoriales - ANOVA de doble vía
=====================================================

Un **experimento factorial tiene 2 o más factores, cada uno con al menos dos niveles**, **con réplicas** en cada combinación de niveles de todos los factores. 

Bajo este diseño experimental podemos investigar **interacciones estadísticas**, las cuales se dan si la *respuesta a un factor depende de los niveles de otro factor*. 

Vamos a usar el dataframe *growth*, un ejemplo clásico de diseño factorial balanceado, en el que se evalúan los efectos de las factores dieta (con 3 niveles) y suplemento (con 4 niveles), así como sus posibles interacciones, en la ganancia de peso de animales de granja a las 6 semanas de tratamiento.

Empecemos leyendo los datos crudos y haciendo una exploración de los mismos

```{r}
weights <- read.csv("data/growth.csv")
head(weights)

```


Experimentos factoriales - ANOVA de doble vía: growth
=====================================================

Continuemos explorando el data frame $growth$ ...

```{r}
# hacemos attach para ahorrarnos algo de tecleo
attach(weights)
str(weights)
levels(diet)
levels(supplement)

```

 
Estadísticas de resumen mediante tapply() (R base)
=======================================================
right:55
## $tapply()$
Apply a function to each cell of a ragged array, that is to each (non-empty) group of values given by a unique combination of the levels of certain factors

**Usage**, vean Vean ?tapply para los detalles

tapply(X, INDEX, FUN = NULL, ..., default = NA, simplify = TRUE)

- X an atomic object, typically a vector.
- INDEX a list of one or more factors, each of same length as X. The elements are coerced to factors by as.factor.
- FUN the function to be applied, or NULL. In the case of functions like +, %*%, etc., the function name must be backquoted or quoted. If FUN is NULL, tapply returns a vector which can be used to subscript the multi-way array tapply normally produces.

***

```{r}
# Exploremos los datos usando R base, es decir, la via clasica, usando tapply()
tapply(gain, list(diet, supplement), length)
tapply(gain, list(diet, supplement), mean)
tapply(gain, list(diet, supplement), var)
```

Estadísticas de resumen con barplot() (R base)
=======================================================
right:80
## $barplot$
***
```{r, out.width = '850px', fig.retina = NULL, fig.align='center', echo=TRUE}
# grafiqumemos con barplot de R base
barplot(tapply(gain,list(diet,supplement),mean),beside=T)
```


Estadísticas de resumen con barplot() (R base) - cont.
==================================================
right:80
## $barplot$
Añadir una leyeda e incrementar la escala del eje $y$. 

¿Qué concluyes de estos resultados? 
***
<small>
```{r, out.width = '800px', fig.retina = NULL, fig.align='right', echo=TRUE}
# guardamos valores para la leyenda
labels <- levels(diet)
shade <- c(0.2,0.6,0.9)
# graficamos, esta vez con nombres para los ejes x, y
barplot(tapply(gain,list(diet,supplement),mean),beside=T,
        ylab="weight gain",xlab="supplement",ylim=c(0,30))
# va la leyenda
legend("top", title = "diet", labels,  fill =  gray(shade), horiz = TRUE, cex = 0.7)
```
</small>

Análisis exploratorio usando dplyr() y ggplot()
==================================================
## Tabla de múltiples estadísticos de resumen con $dplyr$

```{r}
# >>> Tabla de resumen de estadisticas descriptivas con dplyr
group_by(weights, diet, supplement) %>% summarise(n = n(),
                                               mean = mean(gain, na.rm = TRUE),
                                             median = median(gain, na.rm = TRUE),
                                           variance = var(gain, na.rm = TRUE),
                                                IQR = IQR(gain, na.rm = TRUE))
```


Gráficas de barras paralelas con 2 variables de agrupamiento con ggplot()
========================================
right:75
## Paqute $ggplot2$
A medida que los graficos se hacen mas complejos, se hace mas facil configurarlos usando $ggplot()$ que con $plot()$
***

```{r, out.width = '850px', fig.retina = NULL, fig.align='center', echo=TRUE}
# >>> gaficado con ggplot()
ggplot(weights, aes(x = supplement, y = gain, fill = diet)) + 
  geom_bar(stat = "identity", position = "dodge")
```


ANOVA de doble vía: experimento factorial completo
======================================================
## Ajuste de modelo ANOVA a diseño factorial factorial de dos vías con $aov()$
Evaluemos el modelo $gain\ \tilde\ diet * supplement$, que contempla todas las interacciones con supplement

Estimamos parámetros para los $efectos\ principales$ de cada nivel de $diet$ y de cada nivel de $supplement$, más términos para las interacciónes entre los niveles de ambos factores.
```{r}
model <- aov(gain ~ diet * supplement)
summary(model)
```


De la tabla de ANOVA podemos concluir que no hay evidencia de interacciones entre los niveles de ambos factores (fila $diet:supplement$, $p = .916$). 

Además indica que los efectos de $diet$ y $supplement$ son aditivos y significativos.

Como ya discutimos anteriormente, la desventaja de $summary.aov()$ es que no nos muestra los $tamaños\ de\ los\ efectos$. 

Para evaluar qué niveles de cada factor son significativamente diferentes, necesitamos recurrir a $summay.lm()$.

Evaluación del tamaño de los efectos de cada nivel de cada factor
====================================================
## Resumen del ajuste de modelo ANOVA con $summary.lm()$
```{r}
summary.lm(model)
```

Evaluación del tamaño de los efectos de cada nivel de cada factor
====================================================
<pre>
Recortado de la tabla producida por summary.lm(model)

Call:
aov(formula = gain ~ diet * supplement)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.48756 -1.00368 -0.07452  1.03496  2.68069 

Coefficients:
                              Estimate Std. Error t value Pr(>|t|)    
 (Intercept)                    26.3485     0.6556  40.191  < 2e-16 ***
 dietoats                       -3.0501     0.9271  -3.290 0.002248 ** 
 dietwheat                      -6.7094     0.9271  -7.237 1.61e-08 ***
 supplementcontrol              -3.0518     0.9271  -3.292 0.002237 **
 supplementsupergain            -3.8824     0.9271  -4.187 0.000174 ***
 supplementsupersupp            -0.7732     0.9271  -0.834 0.409816    
 dietoats:supplementcontrol      0.2471     1.3112   0.188 0.851571   <==
 dietwheat:supplementcontrol     0.8183     1.3112   0.624 0.536512   <==
 dietoats:supplementsupergain    0.2470     1.3112   0.188 0.851652   <==
 dietwheat:supplementsupergain   1.2557     1.3112   0.958 0.344601   <==
 dietoats:supplementsupersupp   -0.6650     1.3112  -0.507 0.615135   <==
 dietwheat:supplementsupersupp   0.8024     1.3112   0.612 0.544381   <==
</pre>

El modelo evaluado es bastante complejo ya que se estimaron 12 parámetros (filas en la tabla): 6 $efectos\ principales$ y 6 $interacciones$. 

La última columna nos indica dos cosas:

1. enfatiza nuestra conclusión de que ninguna interacción (<==) es significativa
2. sugiere que el $modelo\ minimo\ adecuado$ va a requerir a lo sumo 5 parámetros (filas con asteriscos):
 - un punto de corte (Intercept)
 - una diferencia debida a la avena (oats)
 - una diferencia debida al trigo (wheat)
 - una diferencia debida al control
 - una diferencia debida al suplemento supergain

Evaluación del tamaño de los efectos de cada nivel de cada factor
====================================================
<pre>
Recortado de la tabla producida por summary.lm(model)

Call:
aov(formula = gain ~ diet * supplement)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.48756 -1.00368 -0.07452  1.03496  2.68069 

Coefficients:
                              Estimate Std. Error t value Pr(>|t|)    
 (Intercept)                    26.3485     0.6556  40.191  < 2e-16 ***
 dietoats                       -3.0501     0.9271  -3.290 0.002248 ** 
 dietwheat                      -6.7094     0.9271  -7.237 1.61e-08 ***
 supplementcontrol              -3.0518     0.9271  -3.292 0.002237 **  <==
 supplementsupergain            -3.8824     0.9271  -4.187 0.000174 *** <==
 supplementsupersupp            -0.7732     0.9271  -0.834 0.409816    
 dietoats:supplementcontrol      0.2471     1.3112   0.188 0.851571    
 dietwheat:supplementcontrol     0.8183     1.3112   0.624 0.536512    
 dietoats:supplementsupergain    0.2470     1.3112   0.188 0.851652    
 dietwheat:supplementsupergain   1.2557     1.3112   0.958 0.344601    
 dietoats:supplementsupersupp   -0.6650     1.3112  -0.507 0.615135    
 dietwheat:supplementsupersupp   0.8024     1.3112   0.612 0.544381
</pre>

Una inspección detallada de la tabla muestra que los *tamaños de los efectos* debidos al $control$ y $supergain$ (<==), NO son significativamente diferents entre ellos. 

¿Porqué? 

Ello se infiere aplicando $pruebas\ t\ de\ Student$ "mentalmente" a pares de parámetros (filas de la tabla). 

Veamos cómo se calcula: Ignorando los signos (ambos negativos), vemos que la diferencia en es $dif.tam.efectos=3.88 - 3.05 = .83$. 

Considerando los $errores/ estándar$ asociados a ambos $se = .927$, vemos que son ~ 1. 

Para que la diferencia entre ellos sea significativa, necesitamos $\tilde\ 2\ errores\ estandard$ (Recordemos la regla aproximada de que $t \ge 2$, es significativa, donde $t = \frac{dif\ entre\ medias} {{SE}_{diff}}$

Evaluación del tamaño de los efectos de cada nivel de cada factor
====================================================
right:80
Podemos probarlo formalmente:
***
<small>
```{r}
ctrl <- weights %>% dplyr::filter(supplement == "control")
supg <- weights %>% dplyr::filter(supplement == "supergain")

length(ctrl$gain)
length(supg$gain)

# el valor critico
qt(.927, 22)

# la prueba
t.test(ctrl$gain, supg$gain )
```
</small>

Evaluación del tamaño de los efectos de cada nivel de cada factor
====================================================
¿Porqué llevan estrellas $control$ y $supergain$ si no son significativas entre ellas?

Ello se debe a que los contrastes entre tratamientos comparan todos los *efectos principales* en las filas con la fila *Intercept*, donde, recordemos, cada factor es asignado a su primer nivel en orden alfabético (barley y agrimore, en nuestro caso). 

Cuando (como aquí) varios niveles de un factor son diferentes del *Intercept*, pero no entre ellos, todos obtienen estrellitas de significancia. 

Es por ello que **no podemos simplemente contar las filas con estrellas para determinar el número de niveles o tratamientos significativamente diferentes** para definir el $modelo\ minimo\ adecuado$.

Simplificación del modelo
====================================================
right:80
Empezemos la simplificación del modelo defando fuera los *términos de interacciones*, ya que vimos que no son significativas. 
***
```{r}
model1 <- lm(gain ~ diet + supplement)
summary(model1)
```

Simplificación del modelo, cont.
====================================================
right:60
Podemos verificar con $anova()$ que el modelo simplificado resultante no es significativamente peor que el que incluye todos los términos de las interacciones
***
```{r}
anova(model1,model)
```


Simplificación del modelo, cont.
====================================================
right:60
Inspeccionando las estimas de los parámetros en la tabla de ANOVA, vemos claramente que necesitamos retener los tres niveles de $diet$, ya que:

<small>
$dietoats - dietwheat = -3.0928 - -5.9903 = 2.8975$, 
</small>

que es $>>2$, que con un $std.err = .44$ implica que ($t >> 2$), y por tanto significativa.

Formalmente podemos demostrar que $p < 0.001$, corriendo una $prueba\ t\ de\ Student$
***
```{r}
levels(diet)

barley_dfr <- weights %>% filter(diet == "wheat")
oats_dfr <- weights %>% filter(diet == "oats")

#s la prueba
t.test(barley_dfr$gain, oats_dfr$gain)
```

Simplificación del modelo
====================================================
right:50
En cambio, $supersupp$ no es claramente diferente de $agrimore$ ($dif = -.727$,  con $err.std = .509$). 

Tampoco $supergain$ es claramente diferente del $control$ sin suplemento ($dif = .68$ con $err.std = .51$), como habíamos probado anteriormente. 

Por tanto parece que podemos simplificar el modelo, reemplazando los 4 factores originales de $supplement$ por sólo dos niveles. 

Para ello recodificamos los niveles $agrimore$ y $supersupp$ como *best* y los tratamientos $control$ y $supergain$ como *worst*, de la siguiente manera:
***
```{r}
supp2 <- factor(supplement)
levels(supp2)
levels(supp2)[c(1,4)] <- "best"   # agrimore, supersupp, dif no significativa entre ellos
levels(supp2)[c(2,3)] <- "worst"  # control, supergain, dif no significativa entre ellos
levels(supp2)

```

Simplificación del modelo
====================================================
right:70
Ahora procedemos a ajustar el modelos simplificado a los datos:

Y evaluamos formalmente si el modelo simplificado representa o no un peor ajuste a los datos que model y model1

Voila: $model2$ es el $modelo\ minimo\ adecuado$ que buscábamos, ya que su ajuste no es significativamente peor que los dos precedentes, claramente sobreparametrizados. 
***
```{r}
model2 <- lm(gain ~ diet + supp2)
```

```{r}
anova(model, model1, model2)
```


Simplificación del modelo, cont.
====================================================
right:75
Exploremos los parámetros de $model2$

Como ven, hemos logrado simplificar el modelo inicial de 12 parámetros a uno mucho más fácilmente interpretable de sólo 4. 

Por tanto, si nuestro objetivo es obtener la máxima ganancia en peso, entonces una dieta de avena ($barley$) suplementada con $agrimore$ o $supersupp$ es lo adecuado (escondidos en $Intercept$).
***
```{r}
summary(model2)
```

Simplificación del modelo, cont.
====================================================
Para visualizarlo, podemos usar la ya conocida función $TukeyHSD()$, pasándole el modelo en su formato de anova.

```{r, out.width = '850px', fig.retina = NULL, fig.align='center', echo=TRUE}
aov_model2 <- aov(gain ~ diet + supp2)
TukeyHSD(aov_model2)

detach(weights)
```

ANOVA de doble vía con interacciones
===========================================
right:70
## ANOVA de doble vía con interacciones significativas.

Usaremos el data frame $ToothGrowth$ que viene con R. 

Se evalúa el efecto del ácido ascórbico sobre el crecimiento de dientes. 

<small>
Son 60 conejos asignados al azar a recibir uno de 3 niveles de ascorbato, suministrado en una de dos formas posibles (jugo de naranja o vitamina C). 

Por tanto, cada tratamiento consta de 10 individuos ($10x2x3 = 60$).

Carguemos y exploremos los datos
</small>
***
```{r}
attach(ToothGrowth)
str(ToothGrowth)

table(supp, dose)

```

ANOVA de doble vía con interacciones, cont.
===========================================
right:70
## ANOVA de doble vía con interacciones significativas.

Exploración de datos, cont.

Vemos en las tablas que se trata de un diseño balanceado (misma $n$ para cada celda del diseño), por lo que no tenemos que preocuparnos por el orden en el que comparamos los efectos
***
```{r}
group_by(ToothGrowth, supp, dose) %>% 
            summarize(n = n(),
                   mean = mean(len, na.rm = TRUE),
                   sd   = sd(len, na.rm = TRUE),
                   var  = var(len, na.rm = TRUE)                                                   )

```



ANOVA de doble vía con interacciones
===========================================
right:70
La salida de $str()$ nos muestra que la variable $dose$ está codificada como numérica. 

Necesitamos recodificarla como factor de agrupamiento, para que $aov()$ no la trate como una covariable numérica (ANCOVA)

La salida de $summary(fit)$ nos muestra que tanto los *efectos principales* ($sup$ y $dose$) como las *interacciones* entre estos factores son significativas.
***
```{r}
dose <- factor(dose)
fit <- aov(len ~ supp*dose)
summary(fit)
```


Visualización de interacciones entre factores
==============================================
right:65
Existen varios paquetes para visualizar interacciones, así como la función $interaction.plot()$ del paquete $stats$ del sistema base.

La gráfica muestra la longitud promedio de los dientes para cada suplemento y dosis. Es claro que la longitud de los dientes incrementa con la dosis de ascorbato, independientemente del vehículo. 

A la dosis más alta (2 mg), ambos vehículos producen el mismo crecimiento. Existe una interacción entre el nivel más alto de dosis con la variable $type$. 

En el resto de los niveles, para los dos factores, no existen interacciones, como denota el correr paralelo de las líneas.
***
<small>
```{r, out.width = '750px', fig.retina = NULL, fig.align='center', echo=TRUE}
interaction.plot(dose, supp, len, type = "b",
                 col=c("red", "blue"), pch = c(16,18),
                 main = "Interacciones entre dosis y vehiculo")
```
</small>

Visualización de interacciones entre factores
==============================================
La salida de la función $summary.lm()$ nos confirma que existe una interacción significativa entre $suppVC:dose2$, pero no a la dosis1 o control.
```{r}
summary.lm(fit)
```

Visualización de interacciones entre factores HH::interaction2wt()
==============================================
right:70
## HH::interaction2wt()
El paquete $HH$ provee funciones para un análisis gráfico más sofisticado. 

Despliega boxplots para los *efectos principales* y las interacciones de doble vía para diseños de complejidad arbitraria, siendo por tanto muy útil. 
***
```{r, out.width = '800px', fig.retina = NULL, fig.align='center', echo=TRUE}
HH::interaction2wt(len ~ supp *  dose)
```


Funciones y paquetes de R usados para este documento
==============================================
## **Paquetes y software para investigación reproducible y generación de documentos en múltiples** formatos  

Ver referencias en arhivo html.

* knitr 
* pandoc 
* rmarkdown   

## **Paquetes de uso general para procesamiento y graficado de datos**
* dplyr
* ggplot2

Análisis de la varianza - ANOVA
=====================================================
## **Funciones de paquetes base**
<small>
* abline()
* anova()
* aov()
* arrows()
* attach()
* c()
* cat()
* class()
* coef()
* confint()
* colnames()
* data()
* data.frame()
* df()

*** 

* dim()
* factor()
* head()
* help()
* interaction.plot()
* kruskal.test()
* levels()
* length()
* library()
* lines()
* lm()
* names()
* mean()
* median()
* oneway.test()
* par()
* pairwise.t.test()

***

* plot()
* qf()
* read.csv()
* rep()
* shapiro.test()
* str()
* subset()
* sum()
* summary()
* summary.aov()
* summary.lm()
* table()
* tail()
* tapply()
* t.test()
* tukeyHSD()
* var.test()
</small>

Datos del paquetes base
====================================================
## **datasets [R-datasets]**  
* datasets [R-datasets] 

 ... Ver referencias en el archivo html

Paquetes especializados
====================================================
## **Paquetes especializados**
 ... Ver referencias en el archivo html

* car::leveneTest() 
* car::qqPlot() 
* gplots::plotmeans() 
* multcomp::glht() 
* PMCMR::posthoc.kruskal.nemenyi.test 
* PMCMR::posthoc.kruskal.dunn.test 
* ggpubr::ggboxplot()
* ggpubr::stat_compare_means()
* HH::interaction2wt()

Recursos en línea
=================================================
## **The comprehensive R archive network (CRAN)**
* [CRAN](https://cran.r-project.org/)

## **Cursos**
* [RStudio - online learning](https://www.rstudio.com/online-learning/)
* [datacamp - learning R](https://www.datacamp.com/getting-started?step=2&track=r)
* [swirl - learn R, in R](http://swirlstats.com/)  

## **Consulta**
* [R cookbook](http://www.cookbook-r.com/)
* [QuickR](http://www.statmethods.net/)
* [downloadable books o R and stats](http://www.sats.ucla.edu/stat/books/default.htm#DownR)
* [Use R!](http://www.springer.com/series/6991?detailsPage=titles)
* [Official CRAN documentation](https://cran.r-project.org/manuals.html)
* [r, stackoverflow](http://stackoverflow.com/tags/r/info)  

***

## **Manipulación y graficado de datos con paquetes especializados**
* [plotly and gglplot2 user guide](https://plot.ly/ggplot2/user-guide/)
* [Data wrangling with R and RStudio](https://www.rstudio.com/resources/webinars/data-wrangling-with-r-and-rstudio/)
* [Data wrangling with R and RStudio - cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)
* [Data wrangling with R and RStudio - webinar](http://ucsb-bren.github.io/env-info/wk03_dplyr/wrangling-webinar.pdf) 
* [Bradley C Boehmke - Data wrangling with R](https://www.researchgate.net/publication/296196662_Data_Wrangling_with_R) 


Referencias
=======================================
<pre>
Allaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, Hadley Wickham, Joe Cheng, and Winston Chang. 2018. Rmarkdown: Dynamic Documents for R. https://CRAN.R-project.org/package=rmarkdown.

Crawley, Michael J. 2012. The R book. 2nd ed. Wiley.

———. 2015. Statistics : an introduction using R. 2nd ed. Wiley.

Field, Andy P., Jeremy Miles, and Zoe. Field. 2012. Discovering statistics using R. 1st ed. London: Sage.

Fox, John, Sanford Weisberg, and Brad Price. 2018. Car: Companion to Applied Regression. https://CRAN.R-project.org/package=car.

Heiberger, Richard M. 2017. HH: Statistical Analysis and Data Display: Heiberger and Holland. https://CRAN.R-project.org/package=HH.

Hothorn, Torsten, Frank Bretz, and Peter Westfall. 2008. “Simultaneous Inference in General Parametric Models.” Biometrical Journal 50 (3): 346–63.

Kabacoff, Robert. 2015. R in action : data analysis and graphics with R. 2nd ed. Manning. https://github.com/kabacoff/RiA2 http://www.statmethods.net/.

Kassambara, Alboukadel. 2017. Ggpubr: ’Ggplot2’ Based Publication Ready Plots. http://www.sthda.com/english/rpkgs/ggpubr.

MacFerlane, John. 2016. “Pandoc - a universal document converter.” http://pandoc.org/.

Pohlert, Thorsten. 2014. The Pairwise Multiple Comparison of Mean Ranks Package (Pmcmr). https://CRAN.R-project.org/package=PMCMR.

R Core Team. 2018. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.

Warnes, Gregory R., Ben Bolker, Lodewijk Bonebakker, Robert Gentleman, Wolfgang Huber Andy Liaw, Thomas Lumley, Martin Maechler, et al. 2016. Gplots: Various R Programming Tools for Plotting Data. https://CRAN.R-project.org/package=gplots.

Wickham, Hadley. 2009. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. http://ggplot2.org.

Wickham, Hadley, Romain Francois, Lionel Henry, and Kirill Mueller. 2018. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.

Xie, Yihui. 2018. Knitr: A General-Purpose Package for Dynamic Report Generation in R. https://CRAN.R-project.org/package=knitr.
</pre>

